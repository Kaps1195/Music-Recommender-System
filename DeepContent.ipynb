{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from Recommender.DeepContent.Recommender import ContentRecommender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "False\n",
      "a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender = ContentRecommender('dataset/deep_learning/label_map(boolean_mood).csv', 'dataset/main_song_labels.csv', 'dataset/main_labels.csv', 'dataset/main_user_rating.csv',None,None,None,'Recommender/DeepContent/use5-bestcheckpoint-0.08- 0.35.hdf5','dataset/song_preview/','dataset/deep_learning/label_map(boolean_mood).csv')\n",
    "result = recommender.analyzeNewSong('/home/capt4ce/projects/major_project/dataset/song_preview/TRAAAAW128F429D538-mzm.jmksdiul.aac.p.m4a')\n",
    "result.shape\n",
    "\n",
    "# lModel = SongLabellingModel('Recommender/DeepContent/use5-bestcheckpoint-0.08- 0.35.hdf5','dataset/song_preview/','dataset/deep_learning/label_map(boolean_mood).csv')\n",
    "# model = lModel.getModel()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.59105096e-10,   1.66387973e-10,   2.66231287e-10,\n",
       "          9.65666516e-08,   6.21057858e-11,   2.65521327e-10,\n",
       "          1.67285251e-07,   1.09928552e-10,   1.60224403e-11,\n",
       "          8.36470962e-11,   1.17957883e-11,   1.15742194e-10,\n",
       "          4.89744113e-11,   1.86698157e-11,   4.39599068e-13,\n",
       "          1.09641470e-10,   7.90774043e-12,   9.38518707e-10,\n",
       "          4.58757837e-10,   4.39521336e-12,   4.40008663e-12,\n",
       "          6.72966728e-13,   9.61949357e-12,   2.01099866e-11,\n",
       "          1.78979661e-11,   6.13958120e-11,   6.83188055e-12,\n",
       "          5.60954859e-11,   3.50155040e-12,   9.34340019e-12,\n",
       "          5.50741690e-13,   5.21533305e-09,   8.02132319e-12,\n",
       "          9.76045460e-12,   1.26516722e-12,   7.98293289e-13,\n",
       "          1.04216017e-12,   8.81130835e-13,   1.34466593e-09,\n",
       "          3.66065407e-11,   1.21836976e-11,   3.16821951e-11,\n",
       "          1.18484172e-11,   1.31788336e-09,   9.96600358e-10,\n",
       "          1.25853234e-07,   7.24443652e-08,   4.55768543e-08,\n",
       "          6.94191327e-09,   2.49397586e-10]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_path = 'dataset/deep_learning/label_map(boolean_mood).csv'\n",
    "main_song_label_path = 'dataset/main_song_labels.csv'\n",
    "main_labels_path = 'dataset/main_labels.csv'\n",
    "user_rating_path = 'dataset/main_user_rating.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['track_id',\n",
       " 'song_id',\n",
       " 'title',\n",
       " 'preview_file',\n",
       " 'Alternative & Punk',\n",
       " 'Rock',\n",
       " 'Traditional',\n",
       " 'Urban',\n",
       " 'Pop',\n",
       " 'Other',\n",
       " 'Western Hip-Hop/Rap',\n",
       " 'Metal',\n",
       " 'Western Pop',\n",
       " 'Electronica',\n",
       " 'Punk',\n",
       " 'Indie Rock',\n",
       " 'Alternative',\n",
       " '70s Rock',\n",
       " 'Adult Alternative Rock',\n",
       " 'Electric Blues',\n",
       " 'Country',\n",
       " 'Jazz',\n",
       " 'Contemporary R&B/Soul',\n",
       " 'Alternative Rock',\n",
       " 'Acoustic Blues',\n",
       " '60s Rock',\n",
       " 'Classic Country',\n",
       " 'Emo & Hardcore',\n",
       " 'Mainstream Rock',\n",
       " 'Classic R&B/Soul',\n",
       " 'Synth Pop',\n",
       " 'General Mainstream Rock',\n",
       " 'Pop Punk',\n",
       " 'Adult Alternative Pop',\n",
       " 'Black Metal',\n",
       " 'Old School Hip-Hop/Rap',\n",
       " 'Latin Pop',\n",
       " 'General Latin Pop',\n",
       " 'Brit Rock',\n",
       " 'New Wave Pop',\n",
       " 'Classic Hard Rock',\n",
       " 'Adult Contemporary',\n",
       " 'East Coast Rap',\n",
       " 'European Pop',\n",
       " 'Latin Rock',\n",
       " 'Hard Rock',\n",
       " 'Religious',\n",
       " 'happiness',\n",
       " 'sadness',\n",
       " 'anger',\n",
       " 'neutral',\n",
       " 'slow',\n",
       " 'medium',\n",
       " 'fast']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map_df = pandas.read_csv(label_map_path, sep='\\t')\n",
    "list(label_map_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing song label packed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "song_df = pandas.DataFrame(columns=['track_id', 'song_id', 'title', 'preview_file'])\n",
    "labels_df = pandas.DataFrame(columns=['track_id', 'label'])\n",
    "label_map_df = pandas.read_csv(label_map_path, sep='\\t')\n",
    "print label_map_df.head(4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = label_map_df.columns[4:]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for idx,row in label_map_df.iterrows():\n",
    "    related_labels = []\n",
    "    for lbl in labels:\n",
    "        if row[lbl]!=0:\n",
    "            related_labels.append(lbl)\n",
    "#     song_df.loc[len(song_df)] = [row['track_id'], row['song_id'], row['title'], row['preview_file'], str(related_labels).replace('[','').replace(']','')]\n",
    "    song_df.loc[len(song_df)] = [row['track_id'], row['song_id'], row['title'], row['preview_file']]\n",
    "#     print related_labels\n",
    "    for lbl in related_labels:\n",
    "#         print len(labels_df)\n",
    "        labels_df.loc[len(labels_df)] = [row['track_id'], lbl]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print len(song_df)\n",
    "print len(labels_df)\n",
    "song_df.to_csv(main_song_label_path, sep='\\t', encoding='utf-8', index=False)\n",
    "labels_df.to_csv(main_labels_path, sep='\\t', encoding='utf-8', index=False)\n",
    "print(labels_df.head(5))\n",
    "song_df.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels_df[labels_df['track_id']=='TRAAAAW128F429D538']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Label Vector Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = pandas.read_csv(main_song_label_path, sep='\\t')\n",
    "song_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pandas.read_csv(main_labels_path, sep='\\t')\n",
    "labels_df['label_count'] = 1\n",
    "labels_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = labels_df.groupby(['track_id', 'label'], as_index=False).count().rename(columns={'label_count': 'label_count_TF'})\n",
    "label_distinct = labels_df[['label', 'track_id']].drop_duplicates()\n",
    "print TF.head(10)\n",
    "DF = label_distinct.groupby('label', as_index=False).count().rename(columns={'track_id': 'label_count_DF'})\n",
    "print DF.head(10)\n",
    "a=math.log10(len(np.unique(labels_df['track_id'])))\n",
    "DF['IDF']=a-np.log10(DF['label_count_DF'])\n",
    "print TF.columns\n",
    "print DF.columns\n",
    "TF = pandas.merge(TF,DF,on = 'label', how = 'left', sort = False)\n",
    "TF['TF-IDF']=TF['label_count_TF']*TF['IDF']\n",
    "TF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Vect_len = TF[['track_id', 'TF-IDF']]\n",
    "Vect_len['TF-IDF-Sq'] = Vect_len['TF-IDF']**2\n",
    "Vect_len = Vect_len.groupby(['track_id'], as_index=False).sum().rename(columns={'TF-IDF-Sq':'TF-IDF-Sq-Sum'})[['track_id', 'TF-IDF-Sq-Sum']]\n",
    "print Vect_len.columns\n",
    "Vect_len['vect_len'] = np.sqrt(Vect_len[['TF-IDF-Sq-Sum']].sum(axis=1))\n",
    "\n",
    "TF = pandas.merge(TF, Vect_len, on='track_id', how='left', sort=False)\n",
    "TF['label_wt'] = TF['TF-IDF']/TF['vect_len']\n",
    "TF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Users' Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pandas.read_csv(user_rating_path, sep='\\t')\n",
    "rating_df = rating_df[rating_df['rating']!=0]\n",
    "rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_distinct = rating_df['username'].drop_duplicates()\n",
    "user_profile = pandas.DataFrame()\n",
    "i=1\n",
    "\n",
    "for user in user_distinct:\n",
    "    print(str(i)+' of '+str(len(user_distinct))+' users')\n",
    "    \n",
    "    user_data = rating_df[rating_df['username']==user]\n",
    "    user_data = pandas.merge(user_data,TF, on='track_id', how='inner')\n",
    "    user_data_processed = user_data.groupby('label', as_index=False).sum().rename(columns={'label_wt': 'label_pref'})[['label', 'label_pref']]\n",
    "    user_data_processed['user'] = user\n",
    "    user_profile = user_profile.append(user_data_processed, ignore_index=True)\n",
    "    i+=1\n",
    "print len(user_profile)\n",
    "user_profile.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating cosine similarity for each song-user-pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_users=np.unique(rating_df['username'])\n",
    "label_merge_all=pandas.DataFrame()\n",
    "\n",
    "i=1\n",
    "for user in distinct_users:\n",
    "    \n",
    "    # analizing user data one by one\n",
    "    user_profile_all= user_profile[user_profile['user']==user]\n",
    "    distinct_songs = np.unique(TF['track_id'])\n",
    "    j=1\n",
    "    for song in distinct_songs:\n",
    "\n",
    "        if j%300==0:\n",
    "            print 'song: ', j , 'out of: ', len(distinct_songs) , 'with user: ', i , 'out of: ', len(distinct_users)\n",
    "\n",
    "        # analizing song one by one\n",
    "        TF_song= TF[TF['track_id']==song]\n",
    "        label_merge = pandas.merge(TF_song,user_profile_all,on = 'label', how = 'left', sort = False)\n",
    "        label_merge['label_pref']=label_merge['label_pref'].fillna(0)\n",
    "        \n",
    "        # listing label_value= weight of the label * label profile of the user\n",
    "        label_merge['label_value']=label_merge['label_wt']*label_merge['label_pref']\n",
    "\n",
    "        # getting the label weight of the current user-song pair\n",
    "        label_wt_val=np.sqrt(np.sum(np.square(label_merge['label_wt']), axis=0))\n",
    "        \n",
    "        # getting the label value of the current user-song pair\n",
    "        label_pref_val=np.sqrt(np.sum(np.square(user_profile_all['label_pref']), axis=0))\n",
    "\n",
    "        # summing the label_value (rating) of user-song pair\n",
    "        label_merge_final = label_merge.groupby(['user','track_id']).agg({'label_value': 'sum'}).rename(columns = {'label_value': 'score'}).reset_index()\n",
    "\n",
    "        # score = score / (label weight * label value)\n",
    "        label_merge_final['score']=label_merge_final['score']/(label_wt_val*label_pref_val)\n",
    "\n",
    "        label_merge_all = label_merge_all.append(label_merge_final, ignore_index=True)\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    label_merge_all=label_merge_all.sort_values(by=['user','score']).reset_index(drop=True)\n",
    "    \n",
    "label_merge_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_merge_all.sort_values(by='score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[labels_df['track_id']=='TRAQVDI128F42969C8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[labels_df['track_id']=='TRAAAAW128F429D538']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending (based on user profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
