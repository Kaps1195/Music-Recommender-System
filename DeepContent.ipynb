{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from Recommender.DeepContent.Recommender import ContentRecommender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "False\n",
      "a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender = ContentRecommender('dataset/deep_learning/label_map(boolean_mood).csv', 'dataset/main_song_labels.csv', 'dataset/main_labels.csv', 'dataset/main_user_rating.csv','Recommender/DeepContent/bestcheckpoint-1501.06- 0.34.hdf5','dataset/song_preview/','dataset/deep_learning/label_map(boolean_mood).csv')\n",
    "result = recommender.analyzeNewSong('/home/capt4ce/projects/major_project/dataset/song_preview/TRAAAAW128F429D538-mzm.jmksdiul.aac.p.m4a')\n",
    "result.shape\n",
    "\n",
    "# lModel = SongLabellingModel('Recommender/DeepContent/use5-bestcheckpoint-0.08- 0.35.hdf5','dataset/song_preview/','dataset/deep_learning/label_map(boolean_mood).csv')\n",
    "# model = lModel.getModel()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.35320912e-11,   2.22093854e-11,   3.70711968e-11,\n",
       "          1.44899726e-09,   7.70606062e-12,   6.30183536e-12,\n",
       "          9.40023503e-10,   4.99401258e-12,   1.94591262e-12,\n",
       "          6.15742700e-12,   1.30737299e-13,   1.97304291e-11,\n",
       "          4.66548892e-13,   1.33168337e-11,   8.32503283e-14,\n",
       "          2.00772081e-12,   3.28529543e-12,   2.29648800e-11,\n",
       "          5.67400536e-11,   1.90934467e-13,   7.00692217e-13,\n",
       "          1.02979020e-13,   5.53825302e-12,   6.17326394e-13,\n",
       "          1.42633924e-13,   3.04563102e-12,   2.08396248e-13,\n",
       "          4.15846963e-13,   7.21758553e-15,   1.83430246e-12,\n",
       "          8.42174790e-15,   5.42903361e-11,   3.95715395e-14,\n",
       "          3.24846046e-14,   8.82763338e-15,   3.57355027e-15,\n",
       "          2.68138506e-12,   8.24411408e-14,   1.15010594e-12,\n",
       "          4.29642704e-13,   7.27798626e-14,   5.61179033e-13,\n",
       "          4.03194161e-13,   1.06373202e-10,   1.32802571e-11,\n",
       "          2.11586815e-09,   5.41348744e-09,   6.26232799e-09,\n",
       "          1.29242950e-10,   2.39270669e-11]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.16030283e-03,   3.54593759e-03,   5.91914775e-03,\n",
       "          2.31382728e-01,   1.22997258e-03,   1.00573862e-03,\n",
       "          1.50107190e-01,   7.96898850e-04,   3.10162635e-04,\n",
       "          9.82678845e-04,   2.03061591e-05,   3.15008522e-03,\n",
       "          7.39302704e-05,   2.12592958e-03,   1.27231951e-05,\n",
       "          3.20032501e-04,   5.24042116e-04,   3.66657879e-03,\n",
       "          9.05997120e-03,   2.99187504e-05,   1.11319481e-04,\n",
       "          1.58735729e-05,   8.83805915e-04,   9.80072000e-05,\n",
       "          2.22058734e-05,   4.85771307e-04,   3.27071357e-05,\n",
       "          6.58339268e-05,   5.81898178e-07,   2.92340148e-04,\n",
       "          7.74185025e-07,   8.66878778e-03,   5.74834303e-06,\n",
       "          4.61666514e-06,   8.38998858e-07,   0.00000000e+00,\n",
       "          4.27606632e-04,   1.25939805e-05,   1.83084165e-04,\n",
       "          6.80368976e-05,   1.10512183e-05,   8.90412994e-05,\n",
       "          6.38134588e-05,   1.69856455e-02,   2.12008879e-03,\n",
       "          3.37872088e-01,   8.64452779e-01,   1.00000000e+00,\n",
       "          2.06376035e-02,   3.82022583e-03]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized = (result-np.min(result))/(np.max(result)-np.min(result))\n",
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00995276\n",
      "[(0.23138273, 'Urban'), (0.15010719, 'Western Hip-Hop/Rap')]\n",
      "[(0.33787209, 'anger'), (0.86445278, 'neutral')]\n",
      "[(1.0, 'slow')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Urban', 'Western Hip-Hop/Rap', 'anger', 'neutral', 'slow']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['Alternative & Punk',  'Rock',  'Traditional',  'Urban',  'Pop',  'Other',\n",
    "                        'Western Hip-Hop/Rap', 'Metal', 'Western Pop', 'Electronica', 'Punk', 'Indie Rock', 'Alternative', '70s Rock', 'Adult Alternative Rock', 'Electric Blues',\n",
    "                        'Country', 'Jazz', 'Contemporary R&B/Soul', 'Alternative Rock', 'Acoustic Blues', '60s Rock', 'Classic Country', 'Emo & Hardcore', 'Mainstream Rock', 'Classic R&B/Soul',\n",
    "                        'Synth Pop', 'General Mainstream Rock', 'Pop Punk', 'Adult Alternative Pop', 'Black Metal', 'Old School Hip-Hop/Rap', 'Latin Pop', 'General Latin Pop', 'Brit Rock', 'New Wave Pop',\n",
    "                        'Classic Hard Rock', 'Adult Contemporary', 'East Coast Rap', 'European Pop', 'Latin Rock', 'Hard Rock', 'Religious',\n",
    "                        'happiness', 'sadness', 'anger', 'neutral',\n",
    "                        'slow', 'medium', 'fast']\n",
    "\n",
    "genre_list = labels[:43]\n",
    "mood_list = labels[43:47]\n",
    "tempo_list = labels[47:]\n",
    "\n",
    "genre = normalized[0][:43]\n",
    "mood = normalized[0][43:47]\n",
    "tempo = normalized[0][47:]\n",
    "print(np.average(genre))\n",
    "selected_genre = [(i,j) for (i,j) in zip(genre,genre_list) if i >= np.average(genre)]\n",
    "selected_mood = [(i,j) for (i,j) in zip(mood,mood_list) if i >= np.average(mood)]\n",
    "selected_tempo = [(i,j) for (i,j) in zip(tempo,tempo_list) if i >= np.max(tempo)]\n",
    "\n",
    "print(selected_genre)\n",
    "print(selected_mood)\n",
    "print(selected_tempo)\n",
    "a = []\n",
    "# selected_genre=[i[1] for i in selected_genre]\n",
    "# selected_mood=[i[1] for i in selected_mood]\n",
    "# selected_tempo=[i[1] for i in selected_tempo]\n",
    "a = [i[1] for i in selected_genre]+[i[1] for i in selected_mood]+[i[1] for i in selected_tempo]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_path = 'dataset/deep_learning/label_map(boolean_mood).csv'\n",
    "main_song_label_path = 'dataset/main_song_labels.csv'\n",
    "main_labels_path = 'dataset/main_labels.csv'\n",
    "user_rating_path = 'dataset/main_user_rating.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['track_id',\n",
       " 'song_id',\n",
       " 'title',\n",
       " 'preview_file',\n",
       " 'Alternative & Punk',\n",
       " 'Rock',\n",
       " 'Traditional',\n",
       " 'Urban',\n",
       " 'Pop',\n",
       " 'Other',\n",
       " 'Western Hip-Hop/Rap',\n",
       " 'Metal',\n",
       " 'Western Pop',\n",
       " 'Electronica',\n",
       " 'Punk',\n",
       " 'Indie Rock',\n",
       " 'Alternative',\n",
       " '70s Rock',\n",
       " 'Adult Alternative Rock',\n",
       " 'Electric Blues',\n",
       " 'Country',\n",
       " 'Jazz',\n",
       " 'Contemporary R&B/Soul',\n",
       " 'Alternative Rock',\n",
       " 'Acoustic Blues',\n",
       " '60s Rock',\n",
       " 'Classic Country',\n",
       " 'Emo & Hardcore',\n",
       " 'Mainstream Rock',\n",
       " 'Classic R&B/Soul',\n",
       " 'Synth Pop',\n",
       " 'General Mainstream Rock',\n",
       " 'Pop Punk',\n",
       " 'Adult Alternative Pop',\n",
       " 'Black Metal',\n",
       " 'Old School Hip-Hop/Rap',\n",
       " 'Latin Pop',\n",
       " 'General Latin Pop',\n",
       " 'Brit Rock',\n",
       " 'New Wave Pop',\n",
       " 'Classic Hard Rock',\n",
       " 'Adult Contemporary',\n",
       " 'East Coast Rap',\n",
       " 'European Pop',\n",
       " 'Latin Rock',\n",
       " 'Hard Rock',\n",
       " 'Religious',\n",
       " 'happiness',\n",
       " 'sadness',\n",
       " 'anger',\n",
       " 'neutral',\n",
       " 'slow',\n",
       " 'medium',\n",
       " 'fast']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map_df = pandas.read_csv(label_map_path, sep='\\t')\n",
    "list(label_map_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing song label packed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "song_df = pandas.DataFrame(columns=['track_id', 'song_id', 'title', 'preview_file'])\n",
    "labels_df = pandas.DataFrame(columns=['track_id', 'label'])\n",
    "label_map_df = pandas.read_csv(label_map_path, sep='\\t')\n",
    "print label_map_df.head(4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = label_map_df.columns[4:]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for idx,row in label_map_df.iterrows():\n",
    "    related_labels = []\n",
    "    for lbl in labels:\n",
    "        if row[lbl]!=0:\n",
    "            related_labels.append(lbl)\n",
    "#     song_df.loc[len(song_df)] = [row['track_id'], row['song_id'], row['title'], row['preview_file'], str(related_labels).replace('[','').replace(']','')]\n",
    "    song_df.loc[len(song_df)] = [row['track_id'], row['song_id'], row['title'], row['preview_file']]\n",
    "#     print related_labels\n",
    "    for lbl in related_labels:\n",
    "#         print len(labels_df)\n",
    "        labels_df.loc[len(labels_df)] = [row['track_id'], lbl]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print len(song_df)\n",
    "print len(labels_df)\n",
    "song_df.to_csv(main_song_label_path, sep='\\t', encoding='utf-8', index=False)\n",
    "labels_df.to_csv(main_labels_path, sep='\\t', encoding='utf-8', index=False)\n",
    "print(labels_df.head(5))\n",
    "song_df.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels_df[labels_df['track_id']=='TRAAAAW128F429D538']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Label Vector Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = pandas.read_csv(main_song_label_path, sep='\\t')\n",
    "song_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pandas.read_csv(main_labels_path, sep='\\t')\n",
    "labels_df['label_count'] = 1\n",
    "labels_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = labels_df.groupby(['track_id', 'label'], as_index=False).count().rename(columns={'label_count': 'label_count_TF'})\n",
    "label_distinct = labels_df[['label', 'track_id']].drop_duplicates()\n",
    "print TF.head(10)\n",
    "DF = label_distinct.groupby('label', as_index=False).count().rename(columns={'track_id': 'label_count_DF'})\n",
    "print DF.head(10)\n",
    "a=math.log10(len(np.unique(labels_df['track_id'])))\n",
    "DF['IDF']=a-np.log10(DF['label_count_DF'])\n",
    "print TF.columns\n",
    "print DF.columns\n",
    "TF = pandas.merge(TF,DF,on = 'label', how = 'left', sort = False)\n",
    "TF['TF-IDF']=TF['label_count_TF']*TF['IDF']\n",
    "TF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Vect_len = TF[['track_id', 'TF-IDF']]\n",
    "Vect_len['TF-IDF-Sq'] = Vect_len['TF-IDF']**2\n",
    "Vect_len = Vect_len.groupby(['track_id'], as_index=False).sum().rename(columns={'TF-IDF-Sq':'TF-IDF-Sq-Sum'})[['track_id', 'TF-IDF-Sq-Sum']]\n",
    "print Vect_len.columns\n",
    "Vect_len['vect_len'] = np.sqrt(Vect_len[['TF-IDF-Sq-Sum']].sum(axis=1))\n",
    "\n",
    "TF = pandas.merge(TF, Vect_len, on='track_id', how='left', sort=False)\n",
    "TF['label_wt'] = TF['TF-IDF']/TF['vect_len']\n",
    "TF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Users' Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pandas.read_csv(user_rating_path, sep='\\t')\n",
    "rating_df = rating_df[rating_df['rating']!=0]\n",
    "rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_distinct = rating_df['username'].drop_duplicates()\n",
    "user_profile = pandas.DataFrame()\n",
    "i=1\n",
    "\n",
    "for user in user_distinct:\n",
    "    print(str(i)+' of '+str(len(user_distinct))+' users')\n",
    "    \n",
    "    user_data = rating_df[rating_df['username']==user]\n",
    "    user_data = pandas.merge(user_data,TF, on='track_id', how='inner')\n",
    "    user_data_processed = user_data.groupby('label', as_index=False).sum().rename(columns={'label_wt': 'label_pref'})[['label', 'label_pref']]\n",
    "    user_data_processed['user'] = user\n",
    "    user_profile = user_profile.append(user_data_processed, ignore_index=True)\n",
    "    i+=1\n",
    "print len(user_profile)\n",
    "user_profile.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating cosine similarity for each song-user-pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_users=np.unique(rating_df['username'])\n",
    "label_merge_all=pandas.DataFrame()\n",
    "\n",
    "i=1\n",
    "for user in distinct_users:\n",
    "    \n",
    "    # analizing user data one by one\n",
    "    user_profile_all= user_profile[user_profile['user']==user]\n",
    "    distinct_songs = np.unique(TF['track_id'])\n",
    "    j=1\n",
    "    for song in distinct_songs:\n",
    "\n",
    "        if j%300==0:\n",
    "            print 'song: ', j , 'out of: ', len(distinct_songs) , 'with user: ', i , 'out of: ', len(distinct_users)\n",
    "\n",
    "        # analizing song one by one\n",
    "        TF_song= TF[TF['track_id']==song]\n",
    "        label_merge = pandas.merge(TF_song,user_profile_all,on = 'label', how = 'left', sort = False)\n",
    "        label_merge['label_pref']=label_merge['label_pref'].fillna(0)\n",
    "        \n",
    "        # listing label_value= weight of the label * label profile of the user\n",
    "        label_merge['label_value']=label_merge['label_wt']*label_merge['label_pref']\n",
    "\n",
    "        # getting the label weight of the current user-song pair\n",
    "        label_wt_val=np.sqrt(np.sum(np.square(label_merge['label_wt']), axis=0))\n",
    "        \n",
    "        # getting the label value of the current user-song pair\n",
    "        label_pref_val=np.sqrt(np.sum(np.square(user_profile_all['label_pref']), axis=0))\n",
    "\n",
    "        # summing the label_value (rating) of user-song pair\n",
    "        label_merge_final = label_merge.groupby(['user','track_id']).agg({'label_value': 'sum'}).rename(columns = {'label_value': 'score'}).reset_index()\n",
    "\n",
    "        # score = score / (label weight * label value)\n",
    "        label_merge_final['score']=label_merge_final['score']/(label_wt_val*label_pref_val)\n",
    "\n",
    "        label_merge_all = label_merge_all.append(label_merge_final, ignore_index=True)\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    label_merge_all=label_merge_all.sort_values(by=['user','score']).reset_index(drop=True)\n",
    "    \n",
    "label_merge_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_merge_all.sort_values(by='score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[labels_df['track_id']=='TRAQVDI128F42969C8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[labels_df['track_id']=='TRAAAAW128F429D538']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending (based on user profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
