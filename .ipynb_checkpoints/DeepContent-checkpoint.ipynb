{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from Recommender.DeepContent.Recommender import ContentRecommender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recommender/DeepContent/LabellingModel.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", name=\"conv1\")`\n",
      "  x = Convolution2D(64, 3, 3, border_mode='same', name='conv1')(x)\n",
      "Recommender/DeepContent/LabellingModel.py:87: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(name=\"bn1\", axis=1)`\n",
      "  x = BatchNormalization(axis=channel_axis, mode=0, name='bn1')(x)\n",
      "Recommender/DeepContent/LabellingModel.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", name=\"conv2\")`\n",
      "  x = Convolution2D(128, 3, 3, border_mode='same', name='conv2')(x)\n",
      "Recommender/DeepContent/LabellingModel.py:93: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(name=\"bn2\", axis=1)`\n",
      "  x = BatchNormalization(axis=channel_axis, mode=0, name='bn2')(x)\n",
      "Recommender/DeepContent/LabellingModel.py:98: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", name=\"conv3\")`\n",
      "  x = Convolution2D(128, 3, 3, border_mode='same', name='conv3')(x)\n",
      "Recommender/DeepContent/LabellingModel.py:99: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(name=\"bn3\", axis=1)`\n",
      "  x = BatchNormalization(axis=channel_axis, mode=0, name='bn3')(x)\n",
      "Recommender/DeepContent/LabellingModel.py:104: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", name=\"conv4\")`\n",
      "  x = Convolution2D(128, 3, 3, border_mode='same', name='conv4')(x)\n",
      "Recommender/DeepContent/LabellingModel.py:105: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(name=\"bn4\", axis=1)`\n",
      "  x = BatchNormalization(axis=channel_axis, mode=0, name='bn4')(x)\n",
      "Recommender/DeepContent/LabellingModel.py:110: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", name=\"conv5\")`\n",
      "  x = Convolution2D(64, 3, 3, border_mode='same', name='conv5')(x)\n",
      "Recommender/DeepContent/LabellingModel.py:111: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(name=\"bn5\", axis=1)`\n",
      "  x = BatchNormalization(axis=channel_axis, mode=0, name='bn5')(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n",
      "False\n",
      "a\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Unable to open file (unable to open file: name = 'bestcheckpoint-0.04- 0.34.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8237e6655a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrecommender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContentRecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/deep_learning/label_map(boolean_mood).csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset/main_song_labels.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset/main_labels.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset/main_user_rating.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Recommender/DeepContent/use5-bestcheckpoint-0.08- 0.35.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dataset/song_preview/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dataset/deep_learning/label_map(boolean_mood).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzeNewSong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/capt4ce/projects/major_project/dataset/song_preview/TRAAAAW128F429D538-mzm.jmksdiul.aac.p.m4a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# lModel = SongLabellingModel('Recommender/DeepContent/use5-bestcheckpoint-0.08- 0.35.hdf5','dataset/song_preview/','dataset/deep_learning/label_map(boolean_mood).csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/capt4ce/projects/major_project/Recommender/DeepContent/Recommender.py\u001b[0m in \u001b[0;36manalyzeNewSong\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0manalyzeNewSong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mlModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSongLabellingModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msong_preview_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_map_boolean_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/capt4ce/projects/major_project/Recommender/DeepContent/LabellingModel.pyc\u001b[0m in \u001b[0;36mgetModel\u001b[0;34m(self, train, start)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;31m# return self.model.load_weights(self.model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   2636\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2638\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2640\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (unable to open file: name = 'bestcheckpoint-0.04- 0.34.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "recommender = ContentRecommender('dataset/deep_learning/label_map(boolean_mood).csv', 'dataset/main_song_labels.csv', 'dataset/main_labels.csv', 'dataset/main_user_rating.csv',None,None,None,'Recommender/DeepContent/use5-bestcheckpoint-0.08- 0.35.hdf5','dataset/song_preview/','dataset/deep_learning/label_map(boolean_mood).csv')\n",
    "result = recommender.analyzeNewSong('/home/capt4ce/projects/major_project/dataset/song_preview/TRAAAAW128F429D538-mzm.jmksdiul.aac.p.m4a')\n",
    "result.shape\n",
    "\n",
    "# lModel = SongLabellingModel('Recommender/DeepContent/use5-bestcheckpoint-0.08- 0.35.hdf5','dataset/song_preview/','dataset/deep_learning/label_map(boolean_mood).csv')\n",
    "# model = lModel.getModel()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_path = 'dataset/deep_learning/label_map(boolean_mood).csv'\n",
    "main_song_label_path = 'dataset/main_song_labels.csv'\n",
    "main_labels_path = 'dataset/main_labels.csv'\n",
    "user_rating_path = 'dataset/main_user_rating.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_df = pandas.read_csv(label_map_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing song label packed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "song_df = pandas.DataFrame(columns=['track_id', 'song_id', 'title', 'preview_file'])\n",
    "labels_df = pandas.DataFrame(columns=['track_id', 'label'])\n",
    "label_map_df = pandas.read_csv(label_map_path, sep='\\t')\n",
    "print label_map_df.head(4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = label_map_df.columns[4:]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for idx,row in label_map_df.iterrows():\n",
    "    related_labels = []\n",
    "    for lbl in labels:\n",
    "        if row[lbl]!=0:\n",
    "            related_labels.append(lbl)\n",
    "#     song_df.loc[len(song_df)] = [row['track_id'], row['song_id'], row['title'], row['preview_file'], str(related_labels).replace('[','').replace(']','')]\n",
    "    song_df.loc[len(song_df)] = [row['track_id'], row['song_id'], row['title'], row['preview_file']]\n",
    "#     print related_labels\n",
    "    for lbl in related_labels:\n",
    "#         print len(labels_df)\n",
    "        labels_df.loc[len(labels_df)] = [row['track_id'], lbl]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print len(song_df)\n",
    "print len(labels_df)\n",
    "song_df.to_csv(main_song_label_path, sep='\\t', encoding='utf-8', index=False)\n",
    "labels_df.to_csv(main_labels_path, sep='\\t', encoding='utf-8', index=False)\n",
    "print(labels_df.head(5))\n",
    "song_df.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels_df[labels_df['track_id']=='TRAAAAW128F429D538']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Label Vector Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = pandas.read_csv(main_song_label_path, sep='\\t')\n",
    "song_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pandas.read_csv(main_labels_path, sep='\\t')\n",
    "labels_df['label_count'] = 1\n",
    "labels_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = labels_df.groupby(['track_id', 'label'], as_index=False).count().rename(columns={'label_count': 'label_count_TF'})\n",
    "label_distinct = labels_df[['label', 'track_id']].drop_duplicates()\n",
    "print TF.head(10)\n",
    "DF = label_distinct.groupby('label', as_index=False).count().rename(columns={'track_id': 'label_count_DF'})\n",
    "print DF.head(10)\n",
    "a=math.log10(len(np.unique(labels_df['track_id'])))\n",
    "DF['IDF']=a-np.log10(DF['label_count_DF'])\n",
    "print TF.columns\n",
    "print DF.columns\n",
    "TF = pandas.merge(TF,DF,on = 'label', how = 'left', sort = False)\n",
    "TF['TF-IDF']=TF['label_count_TF']*TF['IDF']\n",
    "TF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Vect_len = TF[['track_id', 'TF-IDF']]\n",
    "Vect_len['TF-IDF-Sq'] = Vect_len['TF-IDF']**2\n",
    "Vect_len = Vect_len.groupby(['track_id'], as_index=False).sum().rename(columns={'TF-IDF-Sq':'TF-IDF-Sq-Sum'})[['track_id', 'TF-IDF-Sq-Sum']]\n",
    "print Vect_len.columns\n",
    "Vect_len['vect_len'] = np.sqrt(Vect_len[['TF-IDF-Sq-Sum']].sum(axis=1))\n",
    "\n",
    "TF = pandas.merge(TF, Vect_len, on='track_id', how='left', sort=False)\n",
    "TF['label_wt'] = TF['TF-IDF']/TF['vect_len']\n",
    "TF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Users' Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pandas.read_csv(user_rating_path, sep='\\t')\n",
    "rating_df = rating_df[rating_df['rating']!=0]\n",
    "rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_distinct = rating_df['username'].drop_duplicates()\n",
    "user_profile = pandas.DataFrame()\n",
    "i=1\n",
    "\n",
    "for user in user_distinct:\n",
    "    print(str(i)+' of '+str(len(user_distinct))+' users')\n",
    "    \n",
    "    user_data = rating_df[rating_df['username']==user]\n",
    "    user_data = pandas.merge(user_data,TF, on='track_id', how='inner')\n",
    "    user_data_processed = user_data.groupby('label', as_index=False).sum().rename(columns={'label_wt': 'label_pref'})[['label', 'label_pref']]\n",
    "    user_data_processed['user'] = user\n",
    "    user_profile = user_profile.append(user_data_processed, ignore_index=True)\n",
    "    i+=1\n",
    "print len(user_profile)\n",
    "user_profile.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating cosine similarity for each song-user-pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_users=np.unique(rating_df['username'])\n",
    "label_merge_all=pandas.DataFrame()\n",
    "\n",
    "i=1\n",
    "for user in distinct_users:\n",
    "    \n",
    "    # analizing user data one by one\n",
    "    user_profile_all= user_profile[user_profile['user']==user]\n",
    "    distinct_songs = np.unique(TF['track_id'])\n",
    "    j=1\n",
    "    for song in distinct_songs:\n",
    "\n",
    "        if j%300==0:\n",
    "            print 'song: ', j , 'out of: ', len(distinct_songs) , 'with user: ', i , 'out of: ', len(distinct_users)\n",
    "\n",
    "        # analizing song one by one\n",
    "        TF_song= TF[TF['track_id']==song]\n",
    "        label_merge = pandas.merge(TF_song,user_profile_all,on = 'label', how = 'left', sort = False)\n",
    "        label_merge['label_pref']=label_merge['label_pref'].fillna(0)\n",
    "        \n",
    "        # listing label_value= weight of the label * label profile of the user\n",
    "        label_merge['label_value']=label_merge['label_wt']*label_merge['label_pref']\n",
    "\n",
    "        # getting the label weight of the current user-song pair\n",
    "        label_wt_val=np.sqrt(np.sum(np.square(label_merge['label_wt']), axis=0))\n",
    "        \n",
    "        # getting the label value of the current user-song pair\n",
    "        label_pref_val=np.sqrt(np.sum(np.square(user_profile_all['label_pref']), axis=0))\n",
    "\n",
    "        # summing the label_value (rating) of user-song pair\n",
    "        label_merge_final = label_merge.groupby(['user','track_id']).agg({'label_value': 'sum'}).rename(columns = {'label_value': 'score'}).reset_index()\n",
    "\n",
    "        # score = score / (label weight * label value)\n",
    "        label_merge_final['score']=label_merge_final['score']/(label_wt_val*label_pref_val)\n",
    "\n",
    "        label_merge_all = label_merge_all.append(label_merge_final, ignore_index=True)\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    label_merge_all=label_merge_all.sort_values(by=['user','score']).reset_index(drop=True)\n",
    "    \n",
    "label_merge_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_merge_all.sort_values(by='score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[labels_df['track_id']=='TRAQVDI128F42969C8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[labels_df['track_id']=='TRAAAAW128F429D538']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending (based on user profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
